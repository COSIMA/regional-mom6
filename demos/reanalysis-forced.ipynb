{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regional Tasmania forced by GLORYS and ERA5 reanalysis datasets\n",
    "\n",
    "**Note: FRE-NC tools are required to be set up, as outlined in the `regional-mom6` package [documentation](https://regional-mom6.readthedocs.io/en/latest/).**\n",
    "\n",
    "For this example we need a copy of the [GEBCO bathymetry](https://www.gebco.net/data_and_products/gridded_bathymetry_data/), access to the [GLORYs ocean reanalysis data](https://data.marine.copernicus.eu/product/GLOBAL_MULTIYEAR_PHY_001_030/description), and [ERA5 surface forcing](https://www.ecmwf.int/en/forecasts/dataset/ecmwf-reanalysis-v5). \n",
    "\n",
    "This example reads in the entire global extent of ERA5 and GEBCO; we don't need to worry about cutting it down to size. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does this notebook do?\n",
    "This notebook is designed to set you up with a working MOM6 regional configuration. First, try and get it running with our default Tasmania case, then you can clone the notebook and modify for your region of interest. \n",
    "\n",
    "Input Type | Source | Subsets required\n",
    "---|---|---\n",
    "Surface | [ERA5 surface forcing](https://www.ecmwf.int/en/forecasts/dataset/ecmwf-reanalysis-v5) | Data from 2003; whole globe or subset around our domain\n",
    "Ocean | [GLORYs reanalysis product](https://data.marine.copernicus.eu/product/GLOBAL_MULTIYEAR_PHY_001_030/description) | Boundary segments & initial condition; see section 2 for details.   \n",
    "Bathymetry | [GEBCO](https://www.gebco.net/data_and_products/gridded_bathymetry_data/) | whole globe or subset around domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import regional_mom6 as rmom6\n",
    "from pathlib import Path\n",
    "from dask.distributed import Client\n",
    "client = Client() # Start a dask cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Choose our domain, define workspace paths\n",
    "\n",
    "You can use the <a href=\"https://data.marine.copernicus.eu/product/GLOBAL_MULTIYEAR_PHY_001_030/download\" >graphical user interface (GUI) by Copernicus</a> to find the latitude-longitude extent of the domain of your interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name = \"tasmania-example-reanalysis\"\n",
    "\n",
    "latitude_extent = [-48, -38.95]\n",
    "longitude_extent = [143, 150]\n",
    "\n",
    "date_range = [\"2003-01-01 00:00:00\", \"2003-01-05 00:00:00\"]\n",
    "\n",
    "## Place where all your input files go \n",
    "input_dir = Path(f\"mom6_input_directories/{expt_name}/\")\n",
    "\n",
    "## Directory where you'll run the experiment from\n",
    "run_dir = Path(f\"mom6_run_directories/{expt_name}/\")\n",
    "\n",
    "## Directory where fre tools are stored \n",
    "toolpath_dir = Path(\"PATH_TO_FRE_TOOLS\") ## Compiled tools needed for construction of mask tables\n",
    "\n",
    "## Path to where your raw ocean forcing files are stored\n",
    "glorys_path = Path(\"PATH_TO_GLORYS_DATA\" )\n",
    "\n",
    "for i in [run_dir, glorys_path, input_dir]:\n",
    "    if not os.path.exists(str(i)):\n",
    "        os.makedirs(str(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Prepare ocean forcing data\n",
    "\n",
    "We need to cut out our ocean forcing. The package expects an initial condition and one time-dependent segment per non-land boundary. Naming convention is \"east_unprocessed\" for segments and \"ic_unprocessed\" for the initial condition.\n",
    "\n",
    "Data can be downloaded directly from the [Copernicus Marine data store](https://data.marine.copernicus.eu/product/GLOBAL_MULTIYEAR_PHY_001_030/download) via their GUI (once logged in).\n",
    "\n",
    "1. Initial condition: Using the GUI, select an area matching your `longitude_extent` and `latitude_extent` that corresponds to the first day in your date range. Download the initial condition and save it with filename `ic_unprocessed.nc` inside the `glorys_path` directory.\n",
    "2. Boundary forcing: Using the GUI, select the Eastern boundary of your domain (if you have one that contains ocean). Allow for a buffer of ~0.5 degrees in all directions, and download for the prescribed `date_range`. Download and name `east_unprocessed.nc`.\n",
    "3. Repeat step 2 for the rest sections of the domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Make experiment object\n",
    "The `regional_mom6.experiment` contains the regional domain basics, as well as it generates the horizontal and vertical grids, `hgrid` and `vgrid` respectively, and sets up the directory structures. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt = rmom6.experiment(\n",
    "    longitude_extent = longitude_extent,\n",
    "    latitude_extent = latitude_extent,\n",
    "    date_range = date_range,\n",
    "    resolution = 0.05,\n",
    "    number_vertical_layers = 75,\n",
    "    layer_thickness_ratio = 10,\n",
    "    depth = 4500,\n",
    "    mom_run_dir = run_dir,\n",
    "    mom_input_dir = input_dir,\n",
    "    toolpath_dir = toolpath_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now access the horizontal and vertical grid of the regional configuration via `expt.hgrid` and `expt.vgrid` respectively.\n",
    "\n",
    "By plotting `vgrid` with `marker = '.'` option allows us to inspect the vertical spacing. Alternatively,\n",
    "\n",
    "```python\n",
    "np.diff(expt.vgrid.zl).plot(marker = '.')\n",
    "```\n",
    "shows you the vertical spacing profile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modular workflow!\n",
    "\n",
    "After constructing our `experiment` object, if for some reason we are not happy with the grids, then we can simply modify them and then save them back into the `experiment` object. However, in doing so, we also need to save them to disk again. For example:\n",
    "\n",
    "```python\n",
    "new_hgrid = xr.open_dataset(inputdir / \"hgrid.nc\")\n",
    "```\n",
    "Modify `new_hgrid`, ensuring that _all metadata_ is retained to keep MOM6 happy. Then, save any changes\n",
    "\n",
    "```python\n",
    "expt.hgrid = new_hgrid\n",
    "\n",
    "expt.hgrid.to_netcdf(inputdir / \"hgrid.nc\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Set up bathymetry\n",
    "\n",
    "Similarly to ocean forcing, we point the experiment's `bathymetry` method at the location of the file of choice and also pass a dictionary mapping variable names. We don't don't need to preprocess the bathymatry since it is simply a two-dimensional field and is easier to deal with. Afterwards the bathymetry is stored at `expt.bathymetry`.\n",
    "\n",
    "After running this cell, your input directory will contain other bathymetry-related things like the ocean mosaic and mask table too. This defaults to a 10x10 layout which can be updated later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt.setup_bathymetry(\n",
    "    bathymetry_path='PATH_TO_GEBCO_FILE/GEBCO_2022.nc', \n",
    "    longitude_coordinate_name='lon',\n",
    "    latitude_coordinate_name='lat',\n",
    "    vertical_coordinate_name='elevation',\n",
    "    minimum_layers=1\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check out your domain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-ignore-output",
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "expt.bathymetry.depth.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Step 5: Handle the ocean forcing - where the magic happens\n",
    "\n",
    "This cuts out and interpolates the initial condition as well as all boundaries (unless you don't pass it boundaries).\n",
    "\n",
    "The dictionary maps the MOM6 variable names to what they're called in your ocean input file. Notice how for GLORYs, the horizontal dimensions are `x` and `y`, vs `xh`, `yh`, `xq`, `yq` for ACCESS OM2-01. This is because for an 'A' grid type tracers share the grid with velocities so there's no difference.\n",
    "\n",
    "If one of your segments is land, you can delete its string from the 'boundaries' list. You'll need to update MOM_input to reflect this though so it knows how many segments to look for, and their orientations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a mapping from the GLORYS variables and dimensions to the MOM6 ones\n",
    "ocean_varnames = {\"time\": \"time\",\n",
    "                  \"y\": \"latitude\",\n",
    "                  \"x\": \"longitude\",\n",
    "                  \"zl\": \"depth\",\n",
    "                  \"eta\": \"zos\",\n",
    "                  \"u\": \"uo\",\n",
    "                  \"v\": \"vo\",\n",
    "                  \"tracers\": {\"salt\": \"so\", \"temp\": \"thetao\"}\n",
    "                  }\n",
    "\n",
    "# Set up the initial condition\n",
    "expt.initial_condition(\n",
    "    glorys_path / \"ic_unprocessed.nc\", # directory where the unprocessed initial condition is stored, as defined earlier\n",
    "    ocean_varnames,\n",
    "    gridtype=\"A\"\n",
    "    )\n",
    "\n",
    "# Now iterate through our four boundaries \n",
    "for i, orientation in enumerate([\"south\", \"north\", \"west\", \"east\"]):\n",
    "    expt.rectangular_boundary(\n",
    "        glorys_path / (orientation + \"_unprocessed.nc\"),\n",
    "        ocean_varnames,\n",
    "        orientation,    # Needs to know the cardinal direction of the boundary\n",
    "        i + 1,          # Just a number to identify the boundary. Indexes from 1 \n",
    "        arakawa_grid=\"A\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Run the FRE tools\n",
    "\n",
    "This is just a wrapper for the FRE tools needed to make the mosaics and masks for the experiment. The only thing you need to tell it is the processor layout. In this case we're saying that we want a 10 by 10 grid of 100 processors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt.FRE_tools(layout=(10, 10)) ## Here the tuple defines the processor layout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Set up ERA5 forcing:\n",
    "\n",
    "Here we assume the ERA5 dataset is stored somewhere on the system we are working. \n",
    "\n",
    "Below is a table showing ERA5 characteristics and what needs to be done to sort it out\n",
    "\n",
    "**Required ERA data**:\n",
    "\n",
    "Name | ERA filename | era variable name | Units\n",
    "---|---|---|---\n",
    "Surface Pressure | sp | sp | Pa \n",
    "Surface Temperature | 2t | t2m | K \n",
    "Meridional Wind | 10v | v10 | m/s \n",
    "Zonal Wind | 10u | u10 | m/s \n",
    "Specific Humidity | na | na | kg/kg, calculated from dewpoint temperature\n",
    "Dewpoint Temperature | 2d | d2m | K\n",
    "\n",
    "\n",
    "We calculate specific humidity $q$ from dewpoint temperature $T_d$ and surface pressure $P$ via saturation vapour pressure $P_v$.\n",
    "\n",
    "$$P_v = 10^{8.07131 - \\frac{1730.63}{233.426 + T}} \\frac{101325}{760} \\; \\textrm{[Pascal]} $$\n",
    "\n",
    "$$q = 0.001 \\times 0.622  \\frac{P_v}{P}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "nbval-skip"
    ]
   },
   "outputs": [],
   "source": [
    "expt.setup_era5(\"PATH_TO_ERA5_DATA/era5/single-levels/reanalysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Modify the default input directory to make a (hopefully) runnable configuration out of the box\n",
    "\n",
    "This step copies the default directory, and modifies the `MOM_layout` files to match your experiment by inserting the right number of x,y points and cpu layout. If you use Payu to run mom6, set the `using_payu` flag to `True` and an example `config.yaml` file will be copied to your run directory. This still needs to be modified manually to work with your projects, executable etc.\n",
    "\n",
    "You also need to pass the path to where you git cloned the mom6-regional code. This just ensures that the funciton can find the premade run directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt.setup_run_directory(surface_forcing = \"era5\", using_payu = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Run and Troubleshoot!\n",
    "\n",
    "To do this, navigate to your run directory in the terminal, and use your favourite tool to run the experiment on your system. \n",
    "\n",
    "Hopefully your model is running. If not, the first thing you should do is reduce the timestep. You can do this by adding `#override DT=XXXX` to your `MOM_override` file. \n",
    "\n",
    "If there's strange behaviour on your boundaries, you could play around with the `nudging timescale` (an example is already included in the `MOM_override` file). Sometimes, if your boundary has a lot going on (like all of the eddies spinning off the ACC), it can be hard to avoid these edge effects. This is because the chaotic, submesoscale structures developed within the regional domain won't match those at the boundary. \n",
    "\n",
    "Another thing that can go wrong is little bays creating non-advective cells at your boundaries. Keep an eye out for tiny bays where one side is taken up by a boundary segment. You can either fill them in manually, or move your boundary slightly to avoid them"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
